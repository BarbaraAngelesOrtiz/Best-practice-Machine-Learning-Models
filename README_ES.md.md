# ğŸ“˜ README â€“ GuÃ­a para Modelos de Machine Learning

Este documento define **las reglas mÃ­nimas, estructura y buenas prÃ¡cticas** para trabajar en el desarrollo de modelos de Machine Learning dentro del proyecto.

ğŸ‘‰ EstÃ¡ diseÃ±ado para socios con **experiencia limitada**, aunque sigue **estÃ¡ndares ML reales y profesionales**.

---

## ğŸ¯ Objetivo

- Garantizar que **todos los modelos sean comparables**
- Evitar errores comunes (data leakage, mÃ©tricas inconsistentes, nombres confusos)
- Facilitar anÃ¡lisis, grÃ¡ficos y toma de decisiones
- Ahorrar tiempo en revisiones

> **Regla clave:** si tu modelo no se puede comparar fÃ¡cilmente con otro, estÃ¡ mal implementado.

---

## ğŸ“ Estructura obligatoria del proyecto

```
project/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/            # Datos originales (no modificar)
â”‚   â”œâ”€â”€ processed/      # Datos limpios
â”‚   â””â”€â”€ features/       # Datasets finales para modelos
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_eda.ipynb
â”‚   â”œâ”€â”€ 02_features.ipynb
â”‚   â””â”€â”€ 03_models.ipynb
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_split.py
â”‚   â”œâ”€â”€ train.py
â”‚   â”œâ”€â”€ evaluate.py
â”‚   â””â”€â”€ utils.py
â”œâ”€â”€ models/
â”‚   â””â”€â”€ metrics_summary.csv
â”œâ”€â”€ outputs/
â”‚   â””â”€â”€ plots/
â””â”€â”€ README.md
```

ğŸ“Œ **Importante**
- No modificar `data/raw`
- Todas las mÃ©tricas finales deben guardarse en `models/metrics_summary.csv`
- Todos los grÃ¡ficos van en `outputs/plots/`

---

## ğŸ”¤ ConvenciÃ³n de nombres (CRÃTICO)

### ğŸ”¹ Datasets y splits

Usar **siempre** estos nombres:

```python
X_train, X_test
y_train, y_test
```

Si hay validaciÃ³n:

```python
X_train, X_val, X_test
y_train, y_val, y_test
```

âŒ Incorrecto:
```python
X1, X2, train, test, ytemp
```

---

### ğŸ”¹ Features

Los nombres deben indicar **quÃ© contienen**, no cÃ³mo se crearon.

âœ… Correcto:
```python
features_numeric
features_categorical
X_features_final
```

âŒ Incorrecto:
```python
df2, temp, x
```

---

## ğŸ§  ConvenciÃ³n de nombres de modelos

Cada modelo debe tener un nombre Ãºnico y descriptivo.

```python
model_name = "logreg_v1_baseline"
model_name = "rf_v2_class_weight"
model_name = "xgb_v3_feature_eng"
```

### ğŸ“Œ Formato recomendado

```
<modelo>_<versiÃ³n>_<detalle_clave>
```

Ejemplos:
- `logreg_v1_baseline`
- `rf_v1_no_balance`
- `xgb_v2_tuned`

---

## ğŸ‹ï¸ Entrenamiento del modelo (patrÃ³n Ãºnico)

Todos los modelos deben seguir exactamente este flujo:

```python
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
```

ğŸš« Prohibido:
- Entrenar con `X_test`
- Ajustar hiperparÃ¡metros usando `test`
- Evaluar sin aclarar el set usado

---

## ğŸ“Š MÃ©tricas (estÃ¡ndar obligatorio)

Todas las mÃ©tricas deben guardarse con el mismo formato.

```python
metrics = {
    "model": model_name,
    "accuracy": accuracy_score(y_test, y_pred),
    "precision": precision_score(y_test, y_pred),
    "recall": recall_score(y_test, y_pred),
    "f1": f1_score(y_test, y_pred)
}
```

ğŸ“Œ Si una mÃ©trica no estÃ¡ aquÃ­, **no se compara ni se grafica**.

---

## ğŸ’¾ Guardado de mÃ©tricas (OBLIGATORIO)

Todas las ejecuciones deben agregarse al archivo comÃºn:

```python
metrics_df = pd.DataFrame([metrics])
metrics_df.to_csv(
    "models/metrics_summary.csv",
    mode="a",
    header=False,
    index=False
)
```

âœ” Esto permite:
- Comparar modelos
- Generar grÃ¡ficos automÃ¡ticos
- Versionar resultados

---

## ğŸ“ˆ GrÃ¡ficos

### Reglas

- Un grÃ¡fico por mÃ©trica
- Eje X = modelo
- No mezclar mÃ©tricas

Ejemplo:

```python
sns.barplot(
    data=metrics_df,
    x="model",
    y="f1"
)
plt.xticks(rotation=45)
```

---

## âš ï¸ Errores comunes y cÃ³mo evitarlos

### âŒ Cambiar nombres entre modelos

```python
Xtrain, X_test2
```

âœ” Usar siempre nombres estÃ¡ndar.

---

### âŒ Sobrescribir predicciones

```python
y_pred = model1.predict()
y_pred = model2.predict()
```

âœ” Soluciones:
- Guardar mÃ©tricas directamente
- O usar nombres distintos (`y_pred_lr`, `y_pred_rf`)

---

### âŒ Resultados no reproducibles

âœ” Siempre fijar seed:

```python
RANDOM_STATE = 42
```

---

## âœ… Checklist antes de entregar un modelo

Antes de subir tu trabajo, verificÃ¡:

- [ ] UsÃ© `X_train / X_test`
- [ ] DefinÃ­ `model_name`
- [ ] GuardÃ© mÃ©tricas en `metrics_summary.csv`
- [ ] No entrenÃ© con test
- [ ] FijÃ© `random_state`
- [ ] Los grÃ¡ficos son claros y legibles

---

## ğŸ§  Regla final

> **Si otra persona no puede entender, reproducir y comparar tu modelo en menos de 30 segundos, hay que corregirlo.**

---

ğŸ“Œ Ante dudas, **no improvisar**: preguntar antes de cambiar la estructura o las convenciones.

---

## ğŸ§© FunciÃ³n estÃ¡ndar: `train_and_log_model()`

Para evitar errores y asegurar consistencia, **todos los modelos deben entrenarse y evaluarse usando esta funciÃ³n**.

```python
def train_and_log_model(
    model,
    model_name: str,
    X_train,
    y_train,
    X_test,
    y_test,
    metrics_path: str = "models/metrics_summary.csv"
):
    """
    Entrena un modelo, evalÃºa mÃ©tricas estÃ¡ndar y las guarda para comparaciÃ³n.
    """
    # Entrenamiento
    model.fit(X_train, y_train)

    # PredicciÃ³n
    y_pred = model.predict(X_test)

    # MÃ©tricas estÃ¡ndar
    metrics = {
        "model": model_name,
        "accuracy": accuracy_score(y_test, y_pred),
        "precision": precision_score(y_test, y_pred),
        "recall": recall_score(y_test, y_pred),
        "f1": f1_score(y_test, y_pred)
    }

    # Guardado
    metrics_df = pd.DataFrame([metrics])
    metrics_df.to_csv(
        metrics_path,
        mode="a",
        header=not os.path.exists(metrics_path),
        index=False
    )

    return metrics
```

### âœ” Uso correcto

```python
metrics_lr = train_and_log_model(
    model=logreg,
    model_name="logreg_v1_baseline",
    X_train=X_train,
    y_train=y_train,
    X_test=X_test,
    y_test=y_test
)
```

ğŸ“Œ Beneficios:
- Evita data leakage
- Evita mÃ©tricas inconsistentes
- Facilita grÃ¡ficos automÃ¡ticos
- Permite comparar modelos sin esfuerzo

---

## ğŸš« QuÃ© NO hacer (errores reales y comunes)

### âŒ Entrenar con test (DATA LEAKAGE)

```python
model.fit(X_test, y_test)  # âŒ
```

âœ” Correcto:
```python
model.fit(X_train, y_train)
```

---

### âŒ Cambiar nombres entre notebooks

```python
Xtrain, ytrain
X_test_final
```

âœ” Correcto:
```python
X_train, y_train
X_test, y_test
```

---

### âŒ Comparar modelos con mÃ©tricas distintas

```python
accuracy_lr = accuracy_score(...)
f1_rf = f1_score(...)
```

âœ” Correcto: todos los modelos deben reportar las **mismas mÃ©tricas** usando la funciÃ³n estÃ¡ndar.

---

### âŒ Sobrescribir resultados

```python
y_pred = model1.predict()
y_pred = model2.predict()
```

âœ” Correcto:
- No guardar predicciones
- Guardar mÃ©tricas directamente

---

### âŒ No fijar `random_state`

```python
RandomForestClassifier()
```

âœ” Correcto:
```python
RandomForestClassifier(random_state=42)
```

---

### âŒ GrÃ¡ficos sin contexto

```python
plt.plot(values)
```

âœ” Correcto:
- Eje X = modelo
- TÃ­tulo con mÃ©trica
- Labels claros

---

## ğŸ‘¥ Trabajo colaborativo en el MISMO notebook (OBLIGATORIO)

Como el trabajo se realiza **entre dos personas en un mismo notebook**, es obligatorio usar **parÃ¡metros compartidos**, definidos una sola vez al inicio.

ğŸ‘‰ Esto evita resultados inconsistentes y discusiones innecesarias.

---

## âš™ï¸ Bloque Ãºnico de parÃ¡metros (AL INICIO DEL NOTEBOOK)

Este bloque debe estar en la **primera celda ejecutable** del notebook y **NO debe duplicarse**.

```python
# =========================
# ParÃ¡metros globales
# =========================

RANDOM_STATE = 42
TEST_SIZE = 0.2

# MÃ©tricas
SCORING_REGRESSION = ["rmse", "mae", "r2"]
SCORING_CLASSIFICATION = ["accuracy", "precision", "recall", "f1"]

# KNN
KNN_N_NEIGHBORS = 5
KNN_WEIGHTS = "distance"

# Random Forest
RF_N_ESTIMATORS = 200
RF_MAX_DEPTH = None

# Paths
METRICS_PATH = "models/metrics_summary.csv"
```

ğŸ“Œ **Regla**:
- Nadie hardcodea valores dentro del modelo
- Si se cambia un parÃ¡metro, se cambia **solo acÃ¡**

---

## ğŸ¤ Reglas de convivencia (MUY IMPORTANTES)

### ğŸ‘¤ Partner A â€“ RegresiÃ³n

- Modelos de regresiÃ³n (Linear / Ridge / Lasso, etc.)
- Usa **exactamente** los parÃ¡metros globales
- No redefine `random_state`, `test_size` ni mÃ©tricas

Ejemplo:

```python
from sklearn.linear_model import LinearRegression

reg_model = LinearRegression()

metrics_reg = train_and_log_model(
    model=reg_model,
    model_name="linreg_v1_baseline",
    X_train=X_train,
    y_train=y_train,
    X_test=X_test,
    y_test=y_test,
    metrics_path=METRICS_PATH
)
```

---

### ğŸ‘¤ Partner B â€“ KNN y Random Forest

- Modelos KNN y Random Forest
- Usa **solo** parÃ¡metros del bloque global

Ejemplo KNN:

```python
from sklearn.neighbors import KNeighborsClassifier

knn = KNeighborsClassifier(
    n_neighbors=KNN_N_NEIGHBORS,
    weights=KNN_WEIGHTS
)
```

Ejemplo Random Forest:

```python
from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier(
    n_estimators=RF_N_ESTIMATORS,
    max_depth=RF_MAX_DEPTH,
    random_state=RANDOM_STATE
)
```

---

## ğŸš« QuÃ© NO hacer en trabajo colaborativo

### âŒ Definir parÃ¡metros dentro del modelo

```python
RandomForestClassifier(n_estimators=100)  # âŒ
```

âœ” Correcto:
```python
RandomForestClassifier(n_estimators=RF_N_ESTIMATORS)
```

---

### âŒ Cambiar parÃ¡metros sin avisar

- Cambiar `KNN_N_NEIGHBORS` sin comunicarlo
- Ajustar `TEST_SIZE` localmente

âœ” Todo cambio debe hacerse en el bloque global y quedar visible.

---

### âŒ Duplicar celdas de entrenamiento

- Una persona no re-entrena el modelo de la otra
- Cada modelo se ejecuta **una sola vez** y se loguea

---

## ğŸ§  Regla final (reforzada)

> **Si un parÃ¡metro no estÃ¡ definido en el bloque global, no existe.**
>
> **Si dos personas obtienen resultados distintos, el notebook estÃ¡ mal estructurado.**

